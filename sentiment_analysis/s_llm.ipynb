{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Initialize the OpenAI client with your API key.\n",
    "client = OpenAI(api_key='key')\n",
    "\n",
    "def classify_review(review):\n",
    "    \"\"\"\n",
    "    Uses GPT-4o-mini to classify the sentiment of a given movie review as either Positive or Negative.\n",
    "    The prompt instructs the model to respond with a single word: 'Positive' or 'Negative'.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Classify the sentiment of the following movie review as either Positive or Negative. \"\n",
    "        \"Only respond with a single word: 'Positive' or 'Negative'.\\n\\n\"\n",
    "        f\"Review: {review}\\n\\nSentiment:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # Using GPT-4o-mini as the cost-effective model\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0  # Deterministic output\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        return \"unknown\"\n",
    "\n",
    "    # Normalize the response to lowercase for reliable matching.\n",
    "    answer = answer.lower()\n",
    "    if \"positive\" in answer:\n",
    "        return \"positive\"\n",
    "    elif \"negative\" in answer:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Load the CSV file from the same folder; it is expected to contain headers \"review\" and \"sentiment\".\n",
    "df_full = pd.read_csv(\"imdb_reviews.csv\")\n",
    "\n",
    "# Randomly sample 1000 rows for evaluation (set random_state for reproducibility)\n",
    "df_sample = df_full.sample(n=1000, random_state=42)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Iterate over the sampled reviews and classify each using GPT-4o-mini.\n",
    "for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n",
    "    review_text = row['review']\n",
    "    prediction = classify_review(review_text)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Add the predictions to the DataFrame.\n",
    "df_sample['prediction'] = predictions\n",
    "\n",
    "# Prepare true and predicted labels in lowercase.\n",
    "y_true = df_sample['sentiment'].apply(lambda s: s.strip().lower())\n",
    "y_pred = df_sample['prediction'].apply(lambda s: s.strip().lower())\n",
    "\n",
    "# Compute the evaluation metrics.\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "# Print the computed metrics.\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Accuracy: {:.2%}\".format(accuracy))\n",
    "print(\"Precision (macro): {:.2%}\".format(precision))\n",
    "print(\"Recall (macro): {:.2%}\".format(recall))\n",
    "print(\"F1 Score (macro): {:.2%}\".format(f1))\n",
    "\n",
    "# Optionally, print a detailed classification report.\n",
    "report = classification_report(y_true, y_pred, zero_division=0)\n",
    "print(\"\\nDetailed Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
